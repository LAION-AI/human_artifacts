{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec5834d8-55bb-4253-b138-f65c59312a49",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8e66f4-0f26-4de8-aae2-6eac7910f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1347025-4d83-473a-a529-452d266b6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('..')\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from PIL import Image, ImageOps\n",
    "\n",
    "from models.unet import build_unet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe6ff1c-c140-4f3d-a778-3bc8cf7572f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)\n",
    "\n",
    "# Load weights\n",
    "model_path = \"./logs/hma_unet/hma_unet.pth\"\n",
    "model = build_unet()\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint)\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc41018-fd89-4b7f-86c3-39d05435ff95",
   "metadata": {},
   "source": [
    "### Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64139ba8-e689-4bf3-a49f-d01a2529dc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(image_path):\n",
    "    assert type(image_path) == str, f\"Should be a path, got: {image_path} which is {type(image_path)}\"\n",
    "    img = Image.open(image_path)\n",
    "    return img\n",
    "\n",
    "\n",
    "def predict(input_image):\n",
    "    \n",
    "    preprocess = transforms.Compose([transforms.Resize((512, 256)),\n",
    "                                     transforms.CenterCrop((512, 256)),\n",
    "                                     transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.5, 0.5, 0.5),\n",
    "                                                          (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    input_tensor = preprocess(input_image)\n",
    "    input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
    "    input_batch = input_batch.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        out = torch.sigmoid(model(input_batch.float()))\n",
    "    \n",
    "    # resize to original image size\n",
    "    out = torch.nn.functional.interpolate(out, \n",
    "                                          size=(input_image.size[1], input_image.size[0]), \n",
    "                                          mode='bicubic',\n",
    "                                          align_corners=True)\n",
    "    out = out.permute(0, 2, 3, 1).squeeze().detach().cpu().numpy() > 0.5\n",
    "    out=(out*255).astype(np.uint8)\n",
    "    out = Image.fromarray(np.uint8(out)).convert('RGB')\n",
    "    return out\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728e8535-3834-4d91-9f33-6cccef9ed003",
   "metadata": {},
   "source": [
    "### Make a prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d10697ac-0f20-416c-bd50-f622865a4875",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"./datasets/human_artifacts/train/humans/3989.png\"\n",
    "image = read_image(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f840cc-bca7-4bd2-a2b2-0bb3ac5bdf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68a2688-fbd3-4d69-8681-055c813f458a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = predict(image)\n",
    "plt.imshow(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "709ca326-054b-48a6-a385-ef6fe5a9ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask.save(\"notebooks/prediction.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9d79eeb-4209-43d8-af80-5b51c55008df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
